{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "LOGGING = True\n",
    "DATA_SET_VER = 2011\n",
    "PERMUTE_DATA_FLAG = True\n",
    "EXP_TYPE = 'out_of_sample'\n",
    "# number of times that each experiment is repeated\n",
    "R = 20\n",
    "# the default value for fraction of data set to be used for training\n",
    "TRAIN_RATIO = 2/3\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for logging and debugging purposes\n",
    "def log(logging_str):\n",
    "    if LOGGING:\n",
    "        print(logging_str)\n",
    "        \n",
    "# reading the raw or the preprocessed data set \n",
    "def read_data_set():\n",
    "    current_dir = os.getcwd()\n",
    "    if DATA_SET_VER == 2011:\n",
    "         data_set_file_name = current_dir + '/dataset/bank/bank-full-preprocessed.csv'\n",
    "    elif DATA_SET_VER == 2014:\n",
    "         data_set_file_name = current_dir + '/dataset/bank-additional/bank-additional-full-preprocessed.csv';\n",
    "    else:\n",
    "         data_set_file_name = current_dir + '/dataset/synthetic/synthetic.csv';\n",
    "\n",
    "    data_set_df = pd.read_csv(data_set_file_name,delimiter = ';')\n",
    "    return data_set_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns the training and testing features and target variables based on the specifired training ratio\n",
    "def get_data(train_ratio = TRAIN_RATIO):\n",
    "    data_set_df = read_data_set()\n",
    "    if PERMUTE_DATA_FLAG:\n",
    "        data_set_df = shuffle(data_set_df)\n",
    "    if EXP_TYPE == \"out_of_sample\":\n",
    "        data_set_rows_no = data_set_df.shape[0]\n",
    "        train_samples_max_index = int(data_set_rows_no * train_ratio)\n",
    "        train_data_df = data_set_df[0:train_samples_max_index]\n",
    "        test_data_df = data_set_df[train_samples_max_index:]\n",
    "        train_y = train_data_df['y'].values\n",
    "        train_x = train_data_df.drop(['y'], axis=1).values\n",
    "        test_y = test_data_df['y'].values\n",
    "        test_x = test_data_df.drop(['y'], axis=1).values\n",
    "    else:\n",
    "        train_data_df = data_set_df\n",
    "        test_data_df = data_set_df.copy()\n",
    "        train_y = train_data_df['y'].values\n",
    "        train_x = train_data_df.drop(['y'], axis=1).values\n",
    "        test_y = test_data_df['y'].values\n",
    "        test_x = test_data_df.drop(['y'], axis=1).values\n",
    "    return train_x,train_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# makes a NN model and returns back the predictred probabilities based on the values passed for the hidden layer size and the activation function \n",
    "def get_skl_nn_predictions(train_x, train_y, test_x, hls_size=(5, 5), activation_function = 'relu'):\n",
    "    skl_nn_model = MLPClassifier(hidden_layer_sizes = hls_size, activation = activation_function)\n",
    "    skl_nn_model.fit(train_x,train_y)\n",
    "    pred_y = skl_nn_model.predict_proba(test_x)\n",
    "    return pred_y\n",
    "\n",
    "# a utility function to make the hidden layers size datastructure based on the sklearn documentation\n",
    "def get_hl_tuple(nn_depth, nn_width):\n",
    "    hl_list = []\n",
    "    for i in range(nn_depth):\n",
    "        hl_list.append(nn_width)\n",
    "    hl_tuple = tuple(hl_list)\n",
    "    return hl_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# makes a LR model and returns back the predictred probabilities\n",
    "def get_skl_lr_predictions(train_x,train_y,test_x):\n",
    "    skl_lr_model = LogisticRegression()\n",
    "    skl_lr_model.fit(train_x,train_y)\n",
    "    #print(skl_lr_mode.coef_)\n",
    "    #print(skl_lr_mode.intercept_)\n",
    "    pred_y = skl_lr_model.predict_proba(test_x)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# studying the effect of the network capacity \n",
    "capacity_list = range(1,7)\n",
    "capacity_list_len = len(capacity_list)\n",
    "\n",
    "skl_lr_auc_score = 0 \n",
    "for i in range(R):\n",
    "    train_x,train_y,test_x,test_y = get_data()\n",
    "    pred_y = get_skl_lr_predictions(train_x, train_y, test_x)\n",
    "    skl_lr_auc_score += roc_auc_score(y_true = test_y, y_score = pred_y[:,1])\n",
    "skl_lr_auc_score /= R\n",
    "lr_line  = np.ones(capacity_list_len) * skl_lr_auc_score\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.ylabel('auc score')\n",
    "plt.xlabel('nn_depth')\n",
    "plt.plot(capacity_list, lr_line, label='logistic_regression')\n",
    "\n",
    "auc_scores =[[0 for x in capacity_list] for y in capacity_list] \n",
    "for nn_width in capacity_list:\n",
    "    for nn_depth in capacity_list:\n",
    "        for i in range(R):\n",
    "            pred_y = get_skl_nn_predictions(train_x, train_y, test_x, hls_size = get_hl_tuple(nn_depth, nn_width))\n",
    "            skl_nn_auc_score = roc_auc_score(y_true = test_y, y_score = pred_y[:,1])\n",
    "            auc_scores[nn_width-1][nn_depth-1] += skl_nn_auc_score\n",
    "        auc_scores[nn_width-1][nn_depth-1] /= R\n",
    "    plt.plot(capacity_list,auc_scores[nn_width-1],label = \"nn_width = \" + str(nn_width))\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=10);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# studying the effect of the network capacity -x axis is for the network width \n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.ylabel('auc score')\n",
    "plt.xlabel('nn_width')\n",
    "plt.plot(capacity_list, lr_line, label='logistic_regression')\n",
    "for nn_depth in capacity_list:\n",
    "    plt.plot(capacity_list,[row[nn_depth-1] for row in auc_scores],label = \"nn_depth = \" + str(nn_depth))\n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=10);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#studying the effect of activation function choice and the training data ratio\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "tr_ratio_list = list(np.arange(0.1,1.0,0.1))\n",
    "tr_ratio_list_len = len(tr_ratio_list)\n",
    "\n",
    "lr_auc_scores = []\n",
    "skl_nn_logistic_auc_scores = []\n",
    "skl_nn_tanh_auc_scores = []\n",
    "skl_nn_relu_auc_scores = []\n",
    "\n",
    "for tr_ratio in tr_ratio_list:\n",
    "    skl_lr_auc_score = 0\n",
    "    skl_nn_logistic_auc_score = 0\n",
    "    skl_nn_tanh_auc_score = 0\n",
    "    skl_nn_relu_auc_score = 0\n",
    "    for i in range(R):\n",
    "        train_x,train_y,test_x,test_y = get_data(train_ratio = tr_ratio)\n",
    "        pred_y = get_skl_lr_predictions(train_x, train_y, test_x)\n",
    "        skl_lr_auc_score += roc_auc_score(y_true = test_y, y_score = pred_y[:,1])\n",
    "        pred_y = get_skl_nn_predictions(train_x, train_y, test_x, hls_size = get_hl_tuple(3,10), activation_function= 'logistic')\n",
    "        skl_nn_logistic_auc_score += roc_auc_score(y_true = test_y, y_score = pred_y[:,1])\n",
    "        pred_y = get_skl_nn_predictions(train_x, train_y, test_x, hls_size = get_hl_tuple(3,10), activation_function= 'tanh')\n",
    "        skl_nn_tanh_auc_score += roc_auc_score(y_true = test_y, y_score = pred_y[:,1])        \n",
    "        pred_y = get_skl_nn_predictions(train_x, train_y, test_x, hls_size = get_hl_tuple(3,10))\n",
    "        skl_nn_relu_auc_score += roc_auc_score(y_true = test_y, y_score = pred_y[:,1])\n",
    "    \n",
    "    lr_auc_scores.append(skl_lr_auc_score/R)\n",
    "    skl_nn_logistic_auc_scores.append(skl_nn_logistic_auc_score/R)\n",
    "    skl_nn_tanh_auc_scores.append(skl_nn_tanh_auc_score/R)\n",
    "    skl_nn_relu_auc_scores.append(skl_nn_relu_auc_score/R)\n",
    "    \n",
    "plt.ylabel('auc score')\n",
    "plt.xlabel('training_data_ratio')\n",
    "plt.plot(tr_ratio_list, lr_auc_scores, label = \"lr\")\n",
    "plt.plot(tr_ratio_list, skl_nn_logistic_auc_scores, label = \"nn logistic 3-10\")\n",
    "plt.plot(tr_ratio_list, skl_nn_tanh_auc_scores, label = \"nn tanh 3-10\")\n",
    "plt.plot(tr_ratio_list, skl_nn_relu_auc_scores, label = \"nn relu 3-10\")\n",
    "plt.legend(loc=\"lower right\", fontsize=10);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
