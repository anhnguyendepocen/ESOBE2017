R.version()
R.version
version
setwd("~/Dropbox/codes.v.2/dataset/bank")
DATA_SET_VER = 2011
PERMUTE_DATA_FLAG = TRUE
EXP_TYPE = 'in_sample'
# number of times that each experiment is repeated
R = 20
# the default value for fraction of data set to be used for training
TRAIN_RATIO = 2/3
require(mxnet)
raw_data <- read.csv('bank-full-preprocessed.csv', header=TRUE,sep=';')
#data <- data[sample(nrow(data)),]
# test <- read.csv('test.csv', header=TRUE)
# train <- data.matrix(train)
# test <- data.matrix(test)
#
# train.x <- train[,-1]
# train.y <- train[,1]
# train.x <- t(train.x/255)
# test <- t(test/255)
# table(train.y)
####
n = dim(raw_data)[1]
set.seed(12345)
id=sample(1:n, floor(n*2/3))
data1 = data.matrix(raw_data)
train=data1
test=data1
train.x = t(train[,-17])
train.y = train[,17]
table(train.y)
test.x = t(test[,-17])
test.y = test[,17]
table(test.y)
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=50)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="tanh")
fc2 <- mx.symbol.FullyConnected(act1, name="fc2", num_hidden=20)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="tanh")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=2)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(0)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y,
ctx=devices, num.round=3, array.batch.size=100,
learning.rate=0.1, momentum=0.5,  eval.metric=mx.metric.accuracy,
initializer=mx.init.uniform(0.07),
epoch.end.callback=mx.callback.log.train.metric(100))
predictions <- predict(model, test.x)
table(predictions)
classification_results = c()
for(i in 1:dim(predictions)[2])
{
if(predictions[1,i] < 0.5)
classification_results = c(classification_results,1)
else
classification_results = c(classification_results,0)
}
table(classification_results)
table(test.y)
DATA_SET_VER = 2011
PERMUTE_DATA_FLAG = TRUE
EXP_TYPE = 'in_sample'
# number of times that each experiment is repeated
R = 20
# the default value for fraction of data set to be used for training
TRAIN_RATIO = 2/3
require(mxnet)
raw_data <- read.csv('bank-full-preprocessed.csv', header=TRUE,sep=';')
#data <- data[sample(nrow(data)),]
# test <- read.csv('test.csv', header=TRUE)
# train <- data.matrix(train)
# test <- data.matrix(test)
#
# train.x <- train[,-1]
# train.y <- train[,1]
# train.x <- t(train.x/255)
# test <- t(test/255)
# table(train.y)
####
n = dim(raw_data)[1]
set.seed(12345)
id=sample(1:n, floor(n*2/3))
data1 = data.matrix(raw_data)
train=data1
test=data1
train.x = t(train[,-17])
train.y = train[,17]
table(train.y)
test.x = t(test[,-17])
test.y = test[,17]
table(test.y)
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=50)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="tanh")
fc2 <- mx.symbol.FullyConnected(act1, name="fc2", num_hidden=20)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="tanh")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=2)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")
devices <- mx.cpu()
mx.set.seed(0)
model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y,
ctx=devices, num.round=3, array.batch.size=100,
learning.rate=0.1, momentum=0.5,  eval.metric=mx.metric.accuracy,
initializer=mx.init.uniform(0.07),
epoch.end.callback=mx.callback.log.train.metric(100))
predictions <- predict(model, test.x)
table(predictions)
classification_results = c()
for(i in 1:dim(predictions)[2])
{
if(predictions[1,i] < 0.5)
classification_results = c(classification_results,1)
else
classification_results = c(classification_results,0)
}
table(classification_results)
table(test.y)
